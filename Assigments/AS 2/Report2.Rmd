---
title: "Econ771 - Empirical Exercise 2"
author: "Nixon Torres Candiales"
date: \today
output: 
  pdf_document:
    latex_engine: lualatex
    keep_tex: true
link-citations: yes
linestretch: 1.25
header-includes:
  - \usepackage{amssymb}
  - \usepackage{amsmath}
  - \usepackage{subfig}
  - \usepackage{booktabs}
fontsize: 12pt
font: Latin Modern Math
editor_options: 
  markdown: 
    wrap: 72
---
```{r setup2, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(include = TRUE)
knitr::opts_chunk$set(cache = TRUE)

# Import the required packages and set the working directory
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, vroom, here, sqldf, ggthemes, fixest, modelsummary, plm, ivmodel, xtable)
#setwd("GitHub/Econ771/Assigments/AS 2")
here::i_am("Main.Rmd")
```

\setstretch{1.5}

# Overview

In this assignment, we're going to work through some applied issues related to instrumental variables. For a long time, IV (or 2SLS) was a very common identification strategy for applied empirical micro, but it fell out of favor as people became more aware of the assumptions underlying the estimator and better understood what IV actually estimates (not the ATE in most cases). People also started to find other strategies that were more compelling in some applications (and of course with some other assumptions). In this assignment, we're going to study the effects of a physician's affiliation with a hospital on physician practice patterns, and we'll instrument for physician affiliation using some specific Medicare payment shocks.

Please "submit" your answers as a GitHub repository link. In this repo, please include a final document with your main answers and analyses in a PDF. Be sure to include in your repository all of your supporting code files. Practice writing good code and showing me only what I would need to recreate your results.

# Resources and data

The data for this assignment comes from three sources:

1.  [MD-PPAS](https://resdac.org/cms-data/files/md-ppas); The Medicare Data on Provider Practice and Specialty includes data on physician specialties, practice IDs, demographics, and place of service. Be sure to follow the link and read the data documentation. We'll use these data to construct a measure of physician integration.

2.  [Medicare Utilization and Payment Data](https://data.cms.gov/provider-summary-by-type-of-service/medicare-physician-other-practitioners/medicare-physician-other-practitioners-by-provider-and-service): These files provide data on the quantities and Medicare spending of each physician and service. We'll use these data to capture total physician-level billing activity, and we'll use the service-level data to measure the revenue effects from our plausibly exogenous policy shock. These data are only available beginning in 2012. These files are large but otherwise relatively clean and easy to use, so there's no separate repo for these data. Note that we will only work with data for MDs, so you can drop a lot of observations with that restriction.

3.  [Physician Fee Schedule 2010 Update](https://github.com/imccart/PFS_Update_2010): Our instrument mainly consists of a shock to physician payments introduced in 2010. The shock further increased payments for services in an outpatient facility compared to services billed in a physician's office. The GitHub repo (linked above) provides code to recreate a dataset with service-specific price shocks introduced by the 2010 fee schedule update. To save us some time, I've posed the final dataset from that repo into our class data folder.


# Questions

1.  Provide and discuss a table of simple summary statistics showing the mean, standard deviation, min, and max of total physician-level Medicare spending, claims, and patients. Use the Medicare utilization and payment data to calculate total spending, claims, and patients at the physician level. The patient counts will include some overlap since the data are by service, but that's OK for our purposes.

```{r Q1, include=TRUE, echo=FALSE, results='asis', comment=NA, warning=FALSE, message=FALSE,}
source('Code/Q1.R')
table1
```



Table 1 shows the summary statistics for the total spending, number of claims and total of patients over the years of interest from 2012 to 2017.

2. Form a proxy for integration using the ratio: \begin{equation}
    INT_{it} = \mathbf{1} \left(\frac{HOPD_{it}}{HOPD_{it} + OFFICE_{it} + ASC_{it}} \geq 0.75\right),
    (\#eq:int)
    \end{equation} where $HOPD_{it}$ reflects the total number of claims in which physician $i$ bills in a hospital outpatient setting, $OFFICE_{it}$ is the total number of claims billed to an office setting, and $ASC_{it}$ is the total number of claims billed to an ambulatory surgery center. As reflected in Equation \@ref(eq:int), you can assume that any physician with at least $75\%$ of claims billed in an outpatient setting is integrated with a hospital. Using this $75\%$ threshold, plot the mean of total physician-level claims for integrated versus non-integrated physicians over time.

```{r Q2, , include=TRUE, echo=FALSE, comment=NA, warning=FALSE, message=FALSE,}
source("Code/Q2.R")
plot1
```

We see that after the price shock implementation the total number of claims increased for unintegrated physicians, whereas for the integrated physicians we so not observe a change in the trend.

3. Estimate the relationship between integration on total physician claims using OLS, with the following specification: \begin{equation}
    y_{it} = \delta INT_{it} + \beta x_{it} + \gamma_{i} + \gamma_{t} + \varepsilon_{it}, 
    (\#eq:ols)
    \end{equation} where $INT_{it}$ is defined in Equation \@ref(eq:int), $x_{it}$ captures time-varying physician characteristics, and $\gamma_{i}$ and $\gamma_{t}$ denote physician and time fixed effects. Please focus on physician's that weren't yet integrated as of 2012, that way we have some pre-integration data for everyone. Impose this restriction for the remaining questions. Feel free to experiment with different covariates in $x_{it}$ or simply omit that term and only include the fixed effects.

```{r Q3, eval=TRUE,results='asis', include=TRUE, comment=NA, warning=FALSE, message=FALSE, echo=FALSE}
source("Code/Q3.R")
etable(mod.ols,
       tex=T, style.tex=style.tex('aer'))
```

The estimation results indicate that integrated physicians submit $0.26\%$ less claims than the unintegrated physicians.


4. How much should we be "worried" about endogeneity here? Extending the work of @altonji2005, @oster2019 derives the expression \begin{equation}
    \delta^{*} \approx \hat{\delta}_{D,x_{1}} - \rho \times \left[\hat{\delta}_{D} - \hat{\delta}_{D,x_{1}}\right] \times \frac{R_{max}^{2} - R_{D,x_{1}}^{2}}{R_{D,x_{1}}^{2} - R_{D}^{2}} \xrightarrow{p} \delta,
    (\#eq:oster)
    \end{equation} where $x_{1}$ captures our observable covariates (or fixed effects in our case); $\delta$ denotes the treatment effect of interest; $\hat{\delta}_{D,x_{1}}$ denotes the coefficient on $D$ from a regression of $y$ on $D$ and $x_{1}$; $R_{D,x_{1}}^{2}$ denotes the $R^{2}$ from that regression; $\hat{\delta}_{D}$ denotes the coefficient on $D$ from a regression of $y$ on $D$ only; $R_{D}^{2}$ reflects the $R^{2}$ from that regression; $R_{max}^{2}$ denotes an unobserved "maximum" $R^{2}$ from a regression of $y$ on $D$, observed covariates $x_{1}$, and some unobserved covariates $x_{2}$; and $\rho$ denotes the degree of selection on observed variables relative to unobserved variables. One approach that Oster suggests is to consider a range of $R^{2}_{max}$ and $\rho$ to bound the estimated treatment effect, where the bounds are given by $\left[ \hat{\delta}_{D,x_{1}}, \delta^{*}(R^{2}_{max}, \rho) \right]$. Construct these bounds based on all combinations of $\rho \in (0, .5, 1, 1.5, 2)$ and $R_{max}^{2} \in (0.5, 0.6, 0.7, 0.8, 0.9, 1)$ and present your results in a table. What do your results say about the extent to which selection on observables could be problematic here? Hint: you can also look into `psacalc` in `Stata` or `robomit` in `R` for implementation of @oster2019 in `Stata` or `R`, respectively.

```{r Q4, eval=TRUE,results='asis', include=TRUE, comment=NA, warning=FALSE, message=FALSE, echo=FALSE}
source('Code/Q4.R')
tab4
gc()
```

From the regression presented in table 1 we see that the $R^2_{D,x_1}$ was 0.91. Thus, we omit $R^2_{max} \leq 0.9$. In all the simulations the bounds remain negative. Thus 

5. Construct the change in Medicare payments achievable for an integrated versus non-integrated physician practice due to the 2010 update to the physician fee schedule, $\Delta P_{it}$. Use this as an instrument for $INT_{it}$ in a 2SLS estimator following the same specification as in Equation \@ref(eq:ols). Present your results along with those of your "first stage" and "reduced form".

Yes, the idea of summing a ratio is a bit odd. But it's easier to think of the instrument as the product of baseline (pre-shock) practice size and the average relative revenue change due to the price shock. In that context, the sum of the ratio is really just an interaction term that incorporates information on the price shock magnitude and baseline practice size. Each of these things alone are poor instruments, but together for the practice it reflects a "better" instrument.

```{r Q5, eval=TRUE,results='asis', include=TRUE, comment=NA, warning=FALSE, message=FALSE, echo=FALSE}
source('Code/Q5.R')
reg.dat.2sls <- reg.dat.2sls %>% filter(!is.na(int)) %>% filter(!is.na(practice_rev_change))

reg_1S <- feols(int ~ practice_rev_change | npi+Year, data=reg.dat.2sls)
reg.dat.2sls$INThat <- reg_1S$fitted.values
reg_2S <- feols(log_y ~ INThat + average_submitted_chrg_amt + 
                         average_medicare_payment_amt| npi+Year, data=reg.dat.2sls)
reg_RF <- feols(log_y ~ practice_rev_change + average_submitted_chrg_amt + 
                         average_medicare_payment_amt | npi+Year, data=reg.dat.2sls)

#etable(reg_1S,reg_RF,reg_2S)
etable(reg_1S, reg_RF, reg_2S,
       tex=T, style.tex=style.tex('aer'))

```

Endogeneity can be a threat for identification if the number of claims affect the decision to merge. Thus, table4 presents the results of the two stage least squares. We observe how the estimates decrease, indicating that the number of claims for unintegrated physicians further decline given the price shock.

6. Assess the "need" for IV by implementing a Durbin-Wu-Hausman test with an augmented regression. Do this by first estimating the regression, $INT_{it} = \lambda \Delta P_{it} + \beta x_{it} + \gamma_{i} + \gamma_{t} + \varepsilon_{it}$, take the residual $\hat{\nu} = INT_{it} - \hat{INT}_{it}$, and run the regression $$y_{it} = \delta INT_{it} + \beta x_{it} + \gamma_{i} + \gamma_{t} + \kappa \hat{\nu} + \varepsilon_{it}.$$ Discuss your results for $\hat{\kappa}$.

```{r Q6, eval=TRUE,results='asis', include=TRUE, comment=NA, warning=FALSE, message=FALSE, echo=FALSE}
source('Code/Q6.R')
etable(mod.DWH,
       tex=T, style.tex=style.tex('aer'))
```

From the Durbin-Wu-Hausman test with an augmented regression we see how $\hat{v}$, the residuals, is significant which implies that there was a systematic component in the error that has not been taken care of and this is also driving the treatment effect. As such, this results might be bias. 

7.  Now let's pay attention to potential issues of weak instruments. As we discussed in class, one issue with weak instruments is that our typical critical values (say, 1.96 for a 95\% confidence interval) from the equation of interest (sometimes called the structural equation) are too low in the presence of a weak first-stage. These issues are presented very clearly and more formally in the Andrews, Stock, and Sun (2019) survey article. For this question, you will consider two forms of inference in the presence of weak instruments:

  -   Present the results of a test of the null, $H_{0}: \delta=0$, using the Anderson-Rubin Wald statistic. Do your conclusions from this test differ from a traditional t-test following 2SLS estimation of Equation \@ref(eq:ols)?
  -   Going back to your 2SLS results...inflate your 2SLS standard errors to form the $tF$ adjusted standard error, following Table 3 in Lee et al. (2021). Repeat the test of the null, $H_{0}: \delta=0$, using standard critical values and the $tF$ adjusted standard error.

```{r Q7, eval=TRUE,results='asis', include=TRUE , comment=NA, warning=FALSE, message=FALSE,}
source('Code/Q7.R')
table7
```

We do not see evidence of weak instruments as presented in the table.

8.  Following the Borusyak and Hull (2021) working paper (BH), we can consider our instrument as a function of some exogenous policy shocks and some possibly endogenous physician characteristics, $\Delta P_{it}=f\left(g_{pt}; z_{ipt}\right)$, where $g_{pt}$ captures overall payment shocks for procedure $p$ at time $t$, and $z_{ip}$ denotes a physician's quantity of different procedures at baseline. We can implement the BH re-centering approach as follows:

  -   Consider hypothetical price changes over a set of possible counterfactuals by assuming that the counterfactuals consist of different allocations of the observed relative price changes. For example, take the vector of all relative price changes, reallocate this vector randomly, and assign new hypothetical relative price changes. Do this 100 times. This isn't "all" possible counterfactuals by any means, but it will be fine for our purposes.
  -   Construct the expected revenue change over all possible realizations from previously, $\mu_{it} = E [\Delta P_{it}]= \sum_{s=1}^{100} \sum_{p} g_{pt}^{s} z_{ip}$.
  -   Re-estimate Equation \@ref(eq:ols) by 2SLS when instrumenting for $INT_{it}$ with $\tilde{\Delta} P_{it} = \Delta P_{it} - \mu_{it}$. Intuitively, this re-centering should isolate variation in the instrument that is only due to the policy and remove variation in our instrument that is due to physician practice styles (the latter of which is not a great instrument).
  
  ```{r Q8, eval=TRUE,results='asis', include=TRUE , comment=NA, warning=FALSE, message=FALSE,}
source('Code/Q8.R')
tab8
```

Following Borusyak and Hull (2021) working paper, we recenter the instrument variable by the expected value of the pseudo instruments simulations. After re-centering the instrument the treatment effect shrinks but we still have a larger negative effect than in table 2. 

9.  Discuss your findings and compare estimates from different estimators.

After all of the analysis and sensitivity tests we can see how the integration to the hospital had a negative effect on the number of claims physician made.


10. Reflect on this assignment. What did you find most challenging? What did you find most surprising?

These empirical assignments are a good opportunity to polish the work flow needed to advance our own research. I enjoyed them all so far. I found working with Rmarkdown for the PDF the most challenging part so far. In this particular case as the objects in memory increased I was constrained by the capacities of my device and as such I am considering on writing the results in a text file and load it later, as is the case when I use latex for the write up. 

But is a good practice to polish my work flow and improve the reproducibility of my research.